{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "MNIST digit classifier.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "n5sw_vkRcurq",
        "colab_type": "code",
        "colab": {},
        "outputId": "7217a7c4-3a45-4cd7-bd60-502bbfae5c64"
      },
      "source": [
        "# importing the same old libraries\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from tqdm import tqdm_notebook # Creates Progress bars\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, log_loss, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import os\n",
        "print(os.listdir(\"../input\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['digit-recognizer']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HANId8oncusH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the new libraries , the ones required for implementing pytorch framework in our model\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "xsyYLWFccusY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the dataset\n",
        "df=pd.read_csv(\"../input/digit-recognizer/train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOzIHAwacusm",
        "colab_type": "code",
        "colab": {},
        "outputId": "b2ef456d-a473-4e70-ae2f-99c47d0f1780"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42000, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ica9VbLBcus8",
        "colab_type": "text"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm8eFAxFcutE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting to numpy array\n",
        "X=df.iloc[:,1:].values\n",
        "Y=df.iloc[:,0].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErH1beUucutZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "a6f99b7d-eb50-4f9a-cb17-ec086d742565"
      },
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 784)\n",
            "(42000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brR4YUOAcuto",
        "colab_type": "code",
        "colab": {},
        "outputId": "e043e5a4-65ce-4a7e-d20a-748c64441235"
      },
      "source": [
        "df.iloc[:,0].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    4684\n",
              "7    4401\n",
              "3    4351\n",
              "9    4188\n",
              "2    4177\n",
              "6    4137\n",
              "0    4132\n",
              "4    4072\n",
              "8    4063\n",
              "5    3795\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g29ovGl5cut4",
        "colab_type": "code",
        "colab": {},
        "outputId": "3dadd5d9-895c-473b-d2ef-ec0d045ef128"
      },
      "source": [
        "# Splitting into Training and Validation datasets \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_val,Y_train,Y_val=train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=0)\n",
        "print(X_train.shape,X_val.shape,Y_train.shape,Y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(33600, 784) (8400, 784) (33600,) (8400,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdAGPSoxcuuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# StandardScaling the data\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_val = sc.transform(X_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJk1_otlcuuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting Numpy arrays to Pytorch Tensors after applying scaling\n",
        "X_train,X_val,Y_train,Y_val = map(torch.tensor,(X_train,X_val,Y_train,Y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI4NGtUAcuuu",
        "colab_type": "code",
        "colab": {},
        "outputId": "8f9088cf-0cba-4b7f-a218-6c0b2fdc59d2"
      },
      "source": [
        "print(type(X_train),type(Y_train),type(X_val),type(Y_val)) # X_train and company are now tensors"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNe9Gh_Fcuu-",
        "colab_type": "text"
      },
      "source": [
        "**Writing the class Feedforward Networks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWa07xJTcuvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FFNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(0)\n",
        "        self.net= nn.Sequential(nn.Linear(784,32),nn.Sigmoid(),nn.Linear(32,16),nn.Sigmoid(),nn.Linear(16,10),nn.Softmax())\n",
        "        \n",
        "    def forward(self,X):\n",
        "        return self.net(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRajyP4vcuvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(y_hat, y):\n",
        "  pred = torch.argmax(y_hat, dim=1)\n",
        "  return (pred == y).float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZwBS65dcuvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(x, y, model, l_r, epochs=1000):\n",
        "    loss_arr=[]\n",
        "    acc_arr=[]\n",
        "    opt=optim.Adamax(fn.parameters(),lr= l_r)\n",
        "    for epochs in range(epochs):\n",
        "        y_hat=fn(x.float())\n",
        "        loss=F.cross_entropy(y_hat, y)\n",
        "        loss_arr.append(loss.item())\n",
        "        acc_arr.append(accuracy(y_hat, y))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    plt.plot(loss_arr, 'r')\n",
        "    plt.plot(acc_arr,'b')\n",
        "    plt.show()\n",
        "    print('Loss before training', loss_arr[0])\n",
        "    print('Loss after training', loss_arr[-1])\n",
        "    print('Accuracy', acc_arr[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCDhR8Uicuvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Taking data to GPU\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "X_train=X_train.to(device)\n",
        "Y_train=Y_train.to(device)\n",
        "X_val=X_val.to(device)\n",
        "Y_val=Y_val.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FNguqmCcuvj",
        "colab_type": "code",
        "colab": {},
        "outputId": "f2c4aaf0-8528-46f5-ad7c-1ba660b78869"
      },
      "source": [
        "fn = FFNetwork()\n",
        "fn.to(device)\n",
        "fit(X_train, Y_train, fn, l_r= 0.05, epochs=300)\n",
        "print(\"Test accuracy:\",accuracy(fn(X_val.float()), Y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGtVJREFUeJzt3X+UVOV9x/H3l4VdhEX5sYvyS34oRNBqgyvRqEjUGCFEa2MUmygmUdqoR1MbU9P0GKNNTzTVpAaqNZGqiQWiGEGPxopiFRVhQRSQoogmLstvBPkhwsLTP74zmWGZ3Z1lZ/fOvft5nfOce+fOZeZ7Gfjs3Wee+1wLISAiIsnSIeoCRESk8BTuIiIJpHAXEUkghbuISAIp3EVEEkjhLiKSQAp3EZEEUriLiCSQwl1EJIE6RvXGFRUVYdCgQVG9vYhILC1atGhTCKGyqf0iC/dBgwZRXV0d1duLiMSSmf0xn/3ULSMikkAKdxGRBFK4i4gkkMJdRCSBFO4iIgmkcBcRSSCFu4hIAsUv3DduhO9+Fz79NOpKRESKVvzC/cUX4d//HS69FPbujboaEZGiFL9w/9rXYPJkmDULLr8c9u2LuiIRkaIT2fQDLXLttbBrF3z/+3DccXDrrVFXJCJSVOJ35p72ve/BxIlw220wb17U1YiIFJX4hrsZTJkCRx8Nf/u3sGdP1BWJiBSN+IY7QNeu8Mtfwttvw69+FXU1IiJFI97hDjB+PIweDf/yL94PLyIiCQh3M/jJT2DdOh9FIyIiCQh3gDPOgLFj4Y47YNu2qKsREYlcMsIdvFtmyxa4666oKxERiVxywn3kSLjkErj7bli/PupqREQilZxwB7j9dti92/vgRUTasWSF+7Bh8O1vw333werVUVcjIhKZZIU7wC23QFmZX9gUQtTViIhEInnh3q8f3HknzJkDU6dGXY2ISCSSF+7gZ+1nnQU33gg1NVFXIyLS5pIZ7h06wK9/DXV18M1vwv79UVckItKmkhnuAMceCz//uXfP3HNP1NWIiLSp5IY7wNVXw1e+AjffDEuXRl2NiEibSXa4m3n3zBFHwNe/7mPgRUTagWSHO0Dv3vBf/+Vn7j/8YdTViIi0ieSHO8C4cXDNNT41wfPPR12NiEirax/hDvCzn/n9VidO9AnGREQSrP2Ee5cu8MgjPqnY3/2drl4VkURrMtzNbICZzTWzFWa23MxuyLGPmdk9ZrbKzN4ys5GtU24LjRzpk4s9+ij89rdRVyMi0mryOXOvA/4hhDAcOBW41sxG1NtnLDA01SYB9xa0ykK66SY4/XS4/nqorY26GhGRVtFkuIcQ1oYQFqfWtwMrgH71drsQeDi4+UB3M+tT8GoLoaTE55zZvVuTi4lIYjWrz93MBgGfBV6v91Q/4MOsxzUc/AOgeAwbBv/6r/DUU+qeEZFEyjvczawcmAl8N4Twcf2nc/yRg06JzWySmVWbWfXGjRubV2mhXX99pntm7dpoaxERKbC8wt3MOuHB/kgI4fEcu9QAA7Ie9wcO6tAOIdwfQqgKIVRVVlYeSr2Fo+4ZEUmwfEbLGPAAsCKEcHcDu80GrkiNmjkV2BZCKP7T4WHD/JZ8Tz7pwyRFRBLCQhNnrGZ2BvAysBRIz537T8DRACGE+1I/ACYD5wO7gG+GEKobe92qqqpQXd3oLm1j3z4YPRpWrIDly6FPcX4PLCICYGaLQghVTe3XsakdQgjzyN2nnr1PAK7Nv7wiUlLic8+cdBJccQX84Q++TUQkxtrPFaqNGTYMpkzxud9vuSXqakREWkzhnvatb8FVV/kQySeeiLoaEZEWUbhn++Uv4ZRT4G/+Bl6vP5RfRCQ+FO7ZOnf2C5v69IHx4+Hdd6OuSETkkCjc6+vd279UBTj7bAW8iMSSwj2XoUP9y9XduzPDJEVEYkTh3pCTToL//V9fP+sseOutaOsREWkGhXtjRozwgC8t9YB/6aWoKxIRyYvCvSnDhsErr8CRR8J558HjuabWEREpLgr3fAwc6AH/2c/CxRfDvcV7LxIREVC4569XL/+Sddw4uOYav5JVM0mKSJFSuDdH165+9eq3vuX3Yr3qKtizJ+qqREQO0uTEYVJPx47w619Dv34e8O+/DzNnQo8eUVcmIvJnOnM/FGZw223w0EMwbx6ceiqsWhV1VSIif6Zwb4krroDnn4fNm+Hkk+E3v1E/vIgUBYV7S515JlRXw4knethfdBG8917UVYlIO6dwL4RBg+DFF+HOO+G552D4cPj7v4c1a6KuTETaKYV7oZSUwE03+URjl1/u0wcPHgwTJ8LLL6u7RkTalMK90Pr2hQce8JCfNMmvaB09GoYM8fHxs2bB9u1RVykiCdfkDbJbS9HcILu17dzpQyUfewxeeMEfd+gAxx3nX8JWVfmVr5/5DFRW+kgcEZEG5HuDbIV7W9qzB1591fvnFy3yL2LXrcs8f8QRPt3wscdC//4+lr5v38yyogLKy/UDQKQdyzfcdRFTWyothTFjvKXV1sKSJd6N8+678M47sGAB/P738OmnB79Gp07Qs6dPh5Be1l+vqMi0ykq/wKqkpK2OUkSKgMI9an37eqsvBPjoIx9xs2aN/xDYvBm2bPFlen31ali40B/n+mEAfqbfs2cm8AcO9N8Qhg71LqHhw/XbgEjCKNyLVTqQe/aEv/iL/P7Mrl2Z4N+0ydvGjZn19ONXX4Vp0zIjeHr1grFjfZz+2WfrLF8kARTuSdKli7cBA5red/duv9jq9df9JiSzZsFvf+vz199+u09t3EGDqUTiSv9726vOneH4432GywcfhLVr/Wy+Y0e49FKfL2f+/KirFJFDpHAX17kzTJjg94p98EGoqYHTTvOgf/ZZ7+rRhVgisaGhkJLb9u3w05/ClCmwbZtvO+ww7/IZOhQ+/3k4/XQYNcq3i0ib0Dh3KYydO/0Wg2+/DR9+6G3ZMlixwp/v1AlGjoRTTvGrcAcNyrTu3TUKR6TANM5dCqNrV78x+HnnHbh982Z47TWfz/6VV7wrZ8eOA/cpL89cgNWnT2bYZ/pxupWXt9nhiLQXCnc5NL16wfjx3iAzLv+DDzLtj3/0L2pra/0HQW1t7rH45eWZoD/qqMx6374+LcPw4dCtWxsenEj8KdylMLLH5Y8cmXufEGDrVg/52loP/nRbt86Xb7wBTz998G8BAwZ4P/+YMfCVr/hvBCLSIPW5S3HascOvzP2///P+/qVLfTz+mjX+g2T0aL/o6pJL1K0j7Yq+UJXkCQFWroTf/Q4eecTn4ena1QP+3HN93P5nPuPDOkUSSuEuyRaC9+NPnQozZmS6cTp0gGOO8dE7Z57pbfhwXW0riaFwl/Zjzx4/i1++3Ltwli3z4F+71p/v1csnSBs2zMfoDxvmbdAgvyJXJEYKNhTSzKYC44ENIYQTcjw/BpgFvJ/a9HgI4bbmlSvSAqWlcMIJ3tJC8BkzX37Z29Kl3pWTviALPNgHDvR29NGZZb9+0Lu3t8pKf32RmMnntOVBYDLwcCP7vBxCGF+QikQKwcy7Z445Bq680reF4DNjvvNOpr3/PvzpT35j89ra3FMsdO+eCfuKCr+pSnbr3v3gbV26+PcBXbpAWZku5pI212S4hxBeMrNBrV+KSCsz8zPxykqfOqG+PXsy8+dv3AgbNnjLXn/vPT/737rVp2jIp1vTLDNjZzrws1tZmbfS0vyWubZ16uS/idRvJSW5t+dqHTroh1CCFKrD8TQzexOoBb4XQlheoNcVaTulpTB4sLd87N/vAZ8O+23bvH38sc+tv3OnL+u37O3pm6zs2ePL7PX0si019kOhpMRbhw7esteLcZtZ4ZeFeq0hQ/x7n9b8KAvwGouBgSGEHWY2DngCGJprRzObBEwCOProowvw1iIR6tAh0w3TWv+eQ4C6utyhn/0Doa6u8bZvX9P7NPXn9u71evbv9+379x/YmtpWV3fof/ZQthWzf/xHn5ivFbU43EMIH2etP21m/2FmFSGETTn2vR+4H3y0TEvfWyTxzLzLpVOnqCuJp/QPo9ZYtuTP9unT6ofe4nA3s6OA9SGEYGaj8DniN7e4MhGRljJrt7eNzGco5DRgDFBhZjXAj4BOACGE+4CLge+YWR3wCTAhRDV4XkREgPxGy1zWxPOT8aGSIiJSJHRNtohIAincRUQSSOEuIpJACncRkQRSuIuIJJDCXUQkgRTuIiIJpHAXEUkghbuISAIp3EVEEkjhLiKSQAp3EZEEUriLiCSQwl1EJIEU7iIiCaRwFxFJIIW7iEgCKdxFRBJI4S4ikkAKdxGRBFK4i4gkkMJdRCSBFO4iIgmkcBcRSSCFu4hIAincRUQSSOEuIpJACncRkQRSuIuIJJDCXUQkgRTuIiIJpHAXEUkghbuISAIp3EVEEkjhLiKSQAp3EZEEajLczWyqmW0ws2UNPG9mdo+ZrTKzt8xsZOHLFBGR5sjnzP1B4PxGnh8LDE21ScC9LS9LRERaoslwDyG8BGxpZJcLgYeDmw90N7M+hSpQRESarxB97v2AD7Me16S2iYhIRAoR7pZjW8i5o9kkM6s2s+qNGzcW4K1FRCSXjgV4jRpgQNbj/kBtrh1DCPcD9wNUVVXl/AEg0l6FAPv2Zdr+/Qc+bqjls1+h9sneLwRv6drrt+Zsb2+vcdllcPXVhfu3k0shwn02cJ2ZTQc+B2wLIawtwOuKtIkQYNcu+Ogj2LLF20cfwccfw+7d8MknvmxsPdfj5gZpOgDizizT6j9ubHtz9o37a+zbV9i/81yaDHczmwaMASrMrAb4EdAJIIRwH/A0MA5YBewCvtlaxYo0Jh3Smzcf2LZsOXC9fohv2QJ79uT3HmVl0Lmzt8MOO3i9WzdfLy2Fjh2hpCR369Ch4eeau1+h9mnua+UKLSkeTYZ7COGyJp4PwLUFq0ikGerq4L//G2bPhrlzPagbUl4OPXtm2ogRmfUePQ5c9uyZCep0cJeVebCJxEEhumVEIvHee3DxxbBkCfTvDxdcAMcdB716HdjSYV1WFnXFIm1H4S6xNHeuB3sI8Oij8NWvqltAJJt+yZRY2bcPbr8dvvhFOPJIWLjQQ17BLnIghbvERnU1nHUW3HILXHopzJ8PxxwTdVUixUndMlLUtm6FZ5+FadNg1izvQ3/4Ybj88qgrEyluCndpFfv2wY4d3rZvP7hlb9+50x9nL7dtgz/9Cdav99fr1Qt+9CO48UY4/PBoj00kDhTu0qgQ4IMPPGg/+cTb9u2waVPutmWLP79rV/7v0bWrD1PMXvboASeeCIMHwxe+AJ/7nI+tFpH8KNylQU89BT/4ASzLOZO/h21FRaaNGOGhfPjhPka8WzcP6/R6/ZYOco0dFyk8hbscJAT4/vfh3/7Nx41PnuzLLl38gp7ycqis9BDXKBWR4qRwl4PcfbcH+3e+A7/4hV9KLyLxonCXAzz+ONx0k48dnzxZXSYicaX/uvJnCxfCN74Bo0b5cEMFu0h86b+vADBvHnzpS37V5+zZ3rcuIvGlcG/H6urg5ZfhhhtgzBgf8fLCC9C7d9SViUhLqc89JkKATz/1G0hs3+7L7PXsZf2bRmTfTCJ9odD27bB2rc9j3rGjd8f84hfQvXvURyoihaBwb0Mh+IU+NTWwZg2sW9dwSOda37u36fcwO/AmEtk3kygr8+GLffv6+PKjjoJTToHzzoMjjmj94xeRtqNwL6BPPoGVK32e8XSA19RkWm2tn33n0rVr5uKfww/3VlGRWU9vz34+13qXLvoiVEQU7i2yd6/PTPjMM/CHP8Cbb/q9MdPKyvwmEv37w2mn+bJfv8y2o47yM+bycl1aLyKFpXA/BLW1cOutMGOGd5l07Aif/zz88z/DCSfA0KEwYIDf/UdXcIpIFBTuzbBrF9x1F9xxh38R+Y1vwPjxcM456rMWkeKicM/T0qXw138Nq1b51Zs//aluFCEixUvhnof58/0Cn65dfRz4F74QdUUiIo1TuDehrg4uucRnQZw71/vSRUSKncK9CU8+CR9+CE88oWAXkfjQiOgm3Huvh/qXvxx1JSIi+VO4N2LdOpgzB6680oc7iojEhcK9ETNn+pQBl14adSUiIs2jcG/E9Olw/PHeRETiROHegDfe8DnOr7gi6kpERJpP4d6An/3M53yZNCnqSkREmk/hnsP06TBtGlx3neY3F5F4UrjXM3MmTJwIZ5wBP/5x1NWIiByadj3Ab98+n3v9zTe9vfqqX4V66qkwaxaUlkZdoYjIoWl34b5jB/znf/oVp4sX+0yP4POpH3cc/OQncOONfvciEZG4alfhvmsXnHgivP8+VFXB1VfDSSd5GzFCgS4iydGuwn3OHA/26dN1YZKIJFteX6ia2flmttLMVpnZzTmev9LMNprZklS7qvClttyTT/p9Ri+6KOpKRERaV5Nn7mZWAkwBvgjUAAvNbHYI4e16u84IIVzXCjUWxP798NRTcP75+qJURJIvnzP3UcCqEMLqEMIeYDpwYeuWVXivveYTgV1wQdSViIi0vnzCvR/wYdbjmtS2+r5qZm+Z2WNmVnQzn0+f7l+YKtxFpD3IJ9wtx7ZQ7/GTwKAQwonAHOChnC9kNsnMqs2seuPGjc2rtAWWLIEZM/xm1t26tdnbiohEJp9wrwGyz8T7A7XZO4QQNocQPk09/BVwcq4XCiHcH0KoCiFUVVZWHkq9zfb003DyybBzJ9xwQ5u8pYhI5PIJ94XAUDMbbGalwARgdvYOZtYn6+EFwIrClXjoNm2Cr3/dx7bX1PiUAiIi7UGTo2VCCHVmdh3wLFACTA0hLDez24DqEMJs4HozuwCoA7YAV7ZizXl75BHYuhUeegh69Ii6GhGRtmMh1O8+bxtVVVWhurq6Vd/j5FTn0KJFrfo2IiJtxswWhRCqmtovsbNCrlzpc8foZhsi0h4lNtyfe86XGvooIu1RYsN9zhwYMgQGD466EhGRtpfIcK+r83nZzz036kpERKKRyHBfvBg+/hjOPjvqSkREopHIcJ83z5dnnhltHSIiUUlkuL/yive19+0bdSUiItFIXLiH4OF++ulRVyIiEp3Ehfvq1bB+vcJdRNq3xIV7ur9d88iISHuWuHB/5RXo3t1veC0i0l4lMtxPOw06JO7IRETyl6gI3LwZ3n5b/e0iIokJ97o6uPxyP2MfOzbqakREotXkfO5x8dRT8MwzMHkyjBwZdTUiItFKzJn7E0/4F6mTJkVdiYhI9BIR7nV1fub+5S9Dp05RVyMiEr1EhPuCBf5l6oUXRl2JiEhxSES4v/aaL0ePjrYOEZFikYhwX7AABg6EI4+MuhIRkeKQmHAfNSrqKkREikfsw33DBvjgA4W7iEi22If7woW+VLiLiGTEPtwXLPCrUnXhkohIRiLC/fjjobw86kpERIpHrMM9BH2ZKiKSS6zDffVq2LJF4S4iUl+sw/2xx3x55pnR1iEiUmxiOStkbS3MnAn33APnnAPDh0ddkYhIcYlduD/zDFx2GWzb5o+nTo22HhGRYhS7bpmhQ/02eosXe/vSl6KuSESk+MTuzP3YY/3sXUREGha7M3cREWmawl1EJIEU7iIiCaRwFxFJoLzC3czON7OVZrbKzG7O8XyZmc1IPf+6mQ0qdKEiIpK/JsPdzEqAKcBYYARwmZmNqLfbt4GPQgjHAj8H7ih0oSIikr98ztxHAatCCKtDCHuA6UD9W1FfCDyUWn8MOMfMrHBliohIc+QT7v2AD7Me16S25dwnhFAHbAN6FaJAERFpvnwuYsp1Bh4OYR/MbBIwKfVwh5mtzOP9c6kANh3iny02OpbipGMpTjoWGJjPTvmEew0wIOtxf6C2gX1qzKwjcASwpf4LhRDuB+7Pp7DGmFl1CKGqpa9TDHQsxUnHUpx0LPnLp1tmITDUzAabWSkwAZhdb5/ZwMTU+sXACyGEg87cRUSkbTR55h5CqDOz64BngRJgaghhuZndBlSHEGYDDwC/MbNV+Bn7hNYsWkREGpfXxGEhhKeBp+ttuyVrfTfwtcKW1qgWd+0UER1LcdKxFCcdS55MvSciIsmj6QdERBIoduHe1FQIxc7MPjCzpWa2xMyqU9t6mtlzZvZuatkj6jpzMbOpZrbBzJZlbctZu7l7Up/TW2Y2MrrKD9bAsdxqZmtSn80SMxuX9dwPUsey0syK5hYxZjbAzOaa2QozW25mN6S2x+5zaeRY4vi5dDazBWb2ZupYfpzaPjg1Rcu7qSlbSlPbCz+FSwghNg3/Qvc9YAhQCrwJjIi6rmYewwdARb1tdwI3p9ZvBu6Ius4Gah8NjASWNVU7MA54Br8G4lTg9ajrz+NYbgW+l2PfEal/a2XA4NS/wZKojyFVWx9gZGq9G/BOqt7YfS6NHEscPxcDylPrnYDXU3/fvwMmpLbfB3wntX4NcF9qfQIwo6U1xO3MPZ+pEOIoe/qGh4C/irCWBoUQXuLg6xcaqv1C4OHg5gPdzaxP21TatAaOpSEXAtNDCJ+GEN4HVuH/FiMXQlgbQlicWt8OrMCvGI/d59LIsTSkmD+XEELYkXrYKdUCcDY+RQsc/LkUdAqXuIV7PlMhFLsA/I+ZLUpdsQtwZAhhLfg/cKB3ZNU1X0O1x/Wzui7VXTE1q3ssFseS+lX+s/hZYqw/l3rHAjH8XMysxMyWABuA5/DfLLYGn6IFDqy34FO4xC3c85rmoMidHkIYic+yea2ZjY66oFYSx8/qXuAY4C+BtcBdqe1FfyxmVg7MBL4bQvi4sV1zbCv2Y4nl5xJC2BdC+Ev8qv5RwPBcu6WWBT+WuIV7PlMhFLUQQm1quQH4Pf6hr0//apxaboiuwmZrqPbYfVYhhPWp/5D7gV+R+RW/qI/FzDrhYfhICOHx1OZYfi65jiWun0taCGEr8CLe597dfIoWOLDePx+LNTKFS3PELdzzmQqhaJlZVzPrll4HzgOWceD0DROBWdFUeEgaqn02cEVqdMapwLZ0N0Gxqtf3fBH+2YAfy4TUiIbBwFBgQVvXl0uqX/YBYEUI4e6sp2L3uTR0LDH9XCrNrHtq/TDgXPw7hLn4FC1w8OdS2Clcov5W+RC+hR6Hf4v+HvDDqOtpZu1D8G/33wSWp+vH+9aeB95NLXtGXWsD9U/Dfy3ei59pfLuh2vFfM6ekPqelQFXU9edxLL9J1fpW6j9bn6z9f5g6lpXA2Kjrz6rrDPzX97eAJak2Lo6fSyPHEsfP5UTgjVTNy4BbUtuH4D+AVgGPAmWp7Z1Tj1elnh/S0hp0haqISALFrVtGRETyoHAXEUkghbuISAIp3EVEEkjhLiKSQAp3EZEEUriLiCSQwl1EJIH+HwgSUYxrnM1kAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss before training 2.3024728298187256\n",
            "Loss after training 1.4908323287963867\n",
            "Accuracy tensor(0.9750, device='cuda:0')\n",
            "Test accuracy: tensor(0.9126, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0zgXnxUcuvs",
        "colab_type": "text"
      },
      "source": [
        "**Applying our Model to test data for submission to Kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLB6ww0ecuvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test=pd.read_csv(\"../input/digit-recognizer/test.csv\")\n",
        "X_test=df_test.values\n",
        "X_test=sc.transform(X_test)\n",
        "X_test=torch.from_numpy(X_test).to(device)# X_test is now a cuda tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tkFyCNMcuv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred_test=fn(X_test.float())\n",
        "Y_pred_test = torch.argmax(Y_pred_test, dim=1)\n",
        "\n",
        "submission = {}\n",
        "submission['ImageId'] = np.array(range(1,X_test.shape[0]+1))\n",
        "submission['Label'] = Y_pred_test.cpu()\n",
        "\n",
        "submission = pd.DataFrame(submission)\n",
        "submission = submission[['ImageId', 'Label']]\n",
        "submission = submission.sort_values(['ImageId'])\n",
        "submission.to_csv(\"submisision.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}